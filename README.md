# LLAMA2_CPU_Impl

### Step 1:
Clone the repository

git clone https://github.com/dtsatyam/LLAMA2_CPU_Impl.git

### Step 2
Create virtual environment

```bash
conda activate -n cpullama python=3.8 -y
```

```bash
conda activate cpullama
```

```bash
pip install -r requirements.txt
```

### Download the quantized llama 2 model and keep in model directory

```ini
## Download the llama 2 model
llama-2-7b-chat.ggmlv3.q4_0.bin

## From following link
https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main
```
